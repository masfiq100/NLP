{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nobel712/NLP/blob/main/Seq2Seq_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zr_86qgmLhVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a514e9-cbec-434a-b9ad-06a184913550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text>=2.11\n",
            "  Downloading tensorflow_text-2.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-text>=2.11) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-text>=2.11) (0.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.32.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (23.3.3)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.3.25)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (23.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (4.5.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (16.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.53.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.12.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (67.6.1)\n",
            "Collecting numpy<1.24,>=1.22\n",
            "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.16.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.20.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (6.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.2.2)\n",
            "Installing collected packages: numpy, tensorflow-text\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.2\n",
            "    Uninstalling numpy-1.24.2:\n",
            "      Successfully uninstalled numpy-1.24.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "orbax 0.1.6 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n",
            "flax 0.6.8 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 tensorflow-text-2.12.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install 'tensorflow-text>=2.11'\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ],
      "metadata": {
        "id": "AwbLwjKUVIu_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "metadata": {
        "id": "2gL_LL2wVsZJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file\n",
        "import pathlib\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzaUubLF8pCG",
        "outputId": "14d6e2a8-996b-402b-c95d-676e4ab200b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2638744/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  text = path.read_text(encoding='utf-8')\n",
        "\n",
        "  lines = text.splitlines()\n",
        "  pairs = [line.split('\\t') for line in lines]\n",
        "\n",
        "  context = np.array([context for target, context in pairs])\n",
        "  target = np.array([target for target, context in pairs])\n",
        "\n",
        "  return target, context"
      ],
      "metadata": {
        "id": "PZvZK32B_nIO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_raw, context_raw = load_data(path_to_file)\n",
        "print(context_raw[-1])"
      ],
      "metadata": {
        "id": "o1cR6-nQakUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7a4902-1146-41a4-9596-74c9c6061e32"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_raw[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6rp6OdLJtYg",
        "outputId": "fc905895-a0a3-457c-e08c-99e8d942a82a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ],
      "metadata": {
        "id": "s_rI4Q5gJ2BI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54u2b23oKJpg",
        "outputId": "c8f3261b-c84d-4a3d-a2f2-9e8fac4d72da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Mu\\xc3\\xa9streme el dinero.' b'Est\\xc3\\xa1s en peligro.'\n",
            " b'El muro no era lo suficientemente alto para impedir la entrada a los perros.'\n",
            " b'Necesito mucho tu ayuda.'\n",
            " b'\\xc2\\xa1T\\xc3\\xba fuiste el que cometi\\xc3\\xb3 el error!'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'Show me the money.' b\"You're in danger.\"\n",
            " b\"The wall wasn't high enough to keep dogs out.\"\n",
            " b'I am badly in need of your help.' b'It was you that made the mistake!'], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvD96nAWKMuw",
        "outputId": "74ab742d-c0e6-43a3-ea6a-0a12edbecf25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Tom se ofreci\\xc3\\xb3 para ayudar a Mary a recuperar su perrito perdido.'\n",
            " b'\\xc2\\xbfQu\\xc3\\xa9 le ha puesto tan triste?'\n",
            " b'Tom dijo que no sab\\xc3\\xada por qu\\xc3\\xa9 a Mary no le gustaba John.'\n",
            " b'Estamos muy agradecidos por lo que hiciste.'\n",
            " b'La polic\\xc3\\xada registr\\xc3\\xb3 el local a fondo.'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'Tom offered to help Mary find her lost puppy.' b'What made her so sad?'\n",
            " b\"Tom said he didn't know why Mary didn't like John.\"\n",
            " b'We are very grateful for what you did.'\n",
            " b'The police searched the premises thoroughly.'], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tf.constant('¿Todavía está en casa?')\n",
        "\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6ZzXXW6LB2w",
        "outputId": "9a8f6fc7-4cdf-4a01-ac8c-e507f18cab98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
            "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ],
      "metadata": {
        "id": "RaNvFUC2KSgg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T21pIuLqKSe_",
        "outputId": "d48c108f-9e2f-4dcb-d1fd-fd2ec82f8413"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Todavía está en casa?\n",
            "[START] ¿ todavia esta en casa ? [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ],
      "metadata": {
        "id": "cO9pVoILKWpo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "context_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHosMb9yKapg",
        "outputId": "91314a51-6239-401b-c206-2434f0290ca0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "target_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otuN_Gx8KbYo",
        "outputId": "a7e0aca9-6d35-4049-f481-ab281be79ff1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "the5_NR_Kfwo",
        "outputId": "a388686a-9cf5-4ca7-9cf6-c8bf26329733"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 10, 17, 2043, 31, 328, 8, 32, 8, 1, 25, 4064, 494, 4, 3],\n",
              " [2, 13, 5, 28, 61, 604, 65, 841, 12, 3],\n",
              " [2, 10, 92, 5, 9, 169, 21, 5, 8, 32, 9, 28, 1006, 233, 4, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "\n",
        "' '.join(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XsT_Dj8hKhqo",
        "outputId": "969419ca-a18b-4eef-fb0b-20a46a334f36"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] tom se ofrecio para ayudar a mary a [UNK] su perrito perdido . [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "6RLRxNXAKkX4",
        "outputId": "7a35f217-95ef-40d7-eb54-74c51e49b5bb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzy0lEQVR4nO3de3xU1b3///fkDiSTcE2IEESloCKoUTGCpxZTAiKCQkW0Fq1Va4MtoKc91Aviz4q3gjcurafFH7aIpecBVCtSihKPNaCCdwRBEdCQoAhJuOQ2s75/cJhmBGHtMLMmk7yej8c8HmbPJ2t/dqcsPqxZn719xhgjAAAARxJinQAAAGhdKD4AAIBTFB8AAMApig8AAOAUxQcAAHCK4gMAADhF8QEAAJyi+AAAAE5RfAAAAKcoPiBJ8vl8mjBhQqzTAABPVq1aJZ/Pp7/+9a+xTgUeUHzEMZ/PZ/VatWpVrFP15KKLLlLfvn3Djp144omh60lISFBWVpbOOOMM3XTTTVqzZk2MMgXw9NNPh/5svvbaa4e9b4xR9+7d5fP5dOmll8YgQzRHSbFOAE33zDPPhP08f/58rVix4rDjp556qsu0oubMM8/UbbfdJkmqrq7WRx99pEWLFumpp57SpEmTNGPGjBhnCLReaWlpWrBggQYNGhR2vKSkRJ9//rlSU1NjlBmaI4qPOPbDH/4w7OfVq1drxYoVhx1vKU444YTDru3BBx/U1VdfrZkzZ6pXr1665ZZbYpQd0LpdcsklWrRokR5//HElJf37r5YFCxYoPz9fX331VQyzQ3PD1y4t3L59+3Tbbbepe/fuSk1NVe/evfXII4/I5mHG9913nxISEvTEE0+Eji1btkwXXnih2rVrp4yMDA0fPlwffvhh2O9dd911Sk9P1xdffKFRo0YpPT1dnTt31u23365AIBDR62vTpo2eeeYZdejQQb/5zW/CrmvhwoXKz89XRkaG/H6/zjjjDD322GMRPT+Ag8aNG6ddu3ZpxYoVoWN1dXX661//qquvvvqw+EceeUQXXHCBOnbsqDZt2ig/P/+I+zZWrFihQYMGKSsrS+np6erdu7d+/etfHzWX2tpaXXrppcrMzNTrr79+/BeHiKP4aMGMMbrssss0c+ZMDR06VDNmzFDv3r31n//5n5o8efJRf/fOO+/U3Xffrd/97ne69dZbJR38mmf48OFKT0/Xgw8+qLvuukvr16/XoEGD9Nlnn4X9fiAQUFFRkTp27KhHHnlE3/3ud/Xb3/5Wv//97yN+nenp6br88sv1xRdfaP369ZIOTljjxo1T+/bt9eCDD+qBBx7QRRddpH/9618RPz+Ag/uyCgoK9Oyzz4aOLVu2TJWVlbrqqqsOi3/sscd01lln6d5779X999+vpKQk/eAHP9Df//73UMyHH36oSy+9VLW1tbr33nv129/+VpdddtlR/xwfOHBAI0aM0Ouvv65//vOfuuCCCyJ7oYgMgxajuLjYNP5IlyxZYiSZ++67LyxuzJgxxufzmc2bN4eOSTLFxcXGGGNuu+02k5CQYJ5++unQ+9XV1SYrK8vceOONYWOVl5ebzMzMsOPjx483ksy9994bFnvWWWeZ/Pz8Y17Hd7/7XXP66aeHHevRo4cZPnz4t/7OzJkzjSSzdOlSY4wxv/jFL4zf7zcNDQ3HPB+Apps3b56RZN58803z5JNPmoyMDLN//35jjDE/+MEPzPe+9z1jzOF/hg/FHFJXV2f69u1rBg8eHDp26M/1l19++a3nf+WVV4wks2jRIlNdXW2++93vmk6dOpm33347gleJSGPlowV78cUXlZiYqJ///Odhx2+77TYZY7Rs2bKw48YYTZgwQY899pj+9Kc/afz48aH3VqxYoT179mjcuHH66quvQq/ExEQNGDBAr7zyymHn/+lPfxr284UXXqhPP/00glf4b+np6ZIObkSVpKysLO3bty9sCRhAdF155ZU6cOCAXnjhBVVXV+uFF1444lcu0sGvTA/ZvXu3KisrdeGFF2rdunWh41lZWZKkpUuXKhgMHvXclZWVGjJkiDZs2KBVq1bpzDPPPO7rQfSw4bQF27p1q3Jzc5WRkRF2/FD3y9atW8OOz58/X3v37tWcOXM0bty4sPc2bdokSRo8ePARz+X3+8N+TktLU+fOncOOtW/fXrt37/Z+IRb27t0rSaFr/dnPfqa//OUvGjZsmE444QQNGTJEV155pYYOHRqV8wOQOnfurMLCQi1YsED79+9XIBDQmDFjjhj7wgsv6L777tM777yj2tra0HGfzxf677Fjx+q///u/9ZOf/ET/9V//pYsvvlhXXHGFxowZo4SE8H87T5w4UTU1NXr77bd1+umnR+cCETGsfCBk4MCBys7O1pNPPqmvv/467L1D/+p45plntGLFisNeS5cuDYtPTEx0lrckffDBB5KkU045RZLUpUsXvfPOO/rb3/6myy67TK+88oqGDRsWtpoDIPKuvvpqLVu2THPnztWwYcNCqxeN/e///q8uu+wypaWlafbs2XrxxRe1YsUKXX311WGbxtu0aaNXX31V//znP3Xttdfqvffe09ixY/X973//sM3rI0eOlDFGDzzwwDFXSRB7FB8tWI8ePVRWVhb6KuKQDRs2hN5v7JRTTtE//vEPlZWVaejQoWG/d/LJJ0s6+Jd6YWHhYa+LLroouhdzFHv37tXixYvVvXv3sHuapKSkaMSIEZo9e7Y++eQT3XzzzZo/f742b94cs1yBlu7yyy9XQkKCVq9e/a1fufzP//yP0tLStHz5cv34xz/WsGHDVFhYeMTYhIQEXXzxxZoxY4bWr1+v3/zmN3r55ZcP+6p31KhR+uMf/6gFCxaouLg44teFyKL4aMEuueQSBQIBPfnkk2HHZ86cKZ/Pp2HDhh32O/369dOLL76ojz76SCNGjNCBAwckSUVFRfL7/br//vtVX19/2O99+eWX0bmIYzhw4ICuvfZaff3117rjjjtCS7a7du0Ki0tISFC/fv0kKWyJF0Bkpaena86cObrnnns0YsSII8YkJibK5/OFrV589tlnWrJkSVjcN1dgJYX2chzpz/GPfvQjPf7445o7d65+9atfNf0iEHXs+WjBRowYoe9973u644479Nlnn6l///76xz/+oaVLl2rixImh1YxvOv/887V06VJdcsklGjNmjJYsWSK/3685c+bo2muv1dlnn62rrrpKnTt31rZt2/T3v/9dAwcOPKzIibQvvvhCf/rTnyQdXO1Yv369Fi1apPLyct122226+eabQ7E/+clP9PXXX2vw4MHq1q2btm7dqieeeEJnnnlmi7njK9BcHevrzeHDh2vGjBkaOnSorr76au3cuVOzZs3SKaecovfeey8Ud++99+rVV1/V8OHD1aNHD+3cuVOzZ89Wt27dDruT6iETJkxQVVWV7rjjDmVmZh7zniCIkdg22yCSvtlqa8zBFtlJkyaZ3Nxck5ycbHr16mUefvhhEwwGw+LUqNX2kKVLl5qkpCQzduxYEwgEjDEH29qKiopMZmamSUtLMyeffLK57rrrzFtvvRX6vfHjx5t27dodlt/UqVMPy+9Ivq3VVpKRZHw+n/H7/eb00083N954o1mzZs1hY/z1r381Q4YMMV26dDEpKSkmLy/P3HzzzWbHjh3HPD8Ae41bbY/mm622f/jDH0yvXr1Mamqq6dOnj5k3b95hc8TKlSvNyJEjTW5urklJSTG5ublm3Lhx5uOPPw7FNG61beyXv/ylkWSefPLJCF0pIslnjMWtLgEAACKEPR8AAMApig8AAOAUxQcAAHCK4gMAADhF8QEAAJyi+AAAAE41u5uMBYNBlZWVKSMjI+wBQwDcMcaourpaubm5hz3Aq7li7gBiy8u80eyKj7KyMnXv3j3WaQCQtH37dnXr1i3WaVhh7gCaB5t5o9kVH4ceiT5IlyhJyTHOBmidGlSv1/Ri6M9jPDiU69Z1J8qfHh+rNZF2+XfOiHUKaMW8zBvNrvg4tFyapGQl+Sg+gJj4v/sex9PXF4dy9acnyJ+RGONsYoM5EzHlYd5onf88AAAAMUPxAQAAnGp2X7t45rOvn3yJ9kuxJhCwits79jzrMdMXrraOBQCvlpe9ax1blNs/ipkAR8fKBwAAcIriAwAAOEXxAQAAnKL4AAAATlF8AAAAp+K/28UDX7L95ZqGequ49OfeaGo6R2fZxZPY9zvWQwbe39DUbAC0MF46Y6KBbpvWjZUPAADgFMUHAABwiuIDAAA4RfEBAACcovgAAABOxX23iy/B/pHfwQMH7Ae+4Ey7869533rIhDbp1rGBvXvt4uhgARBldKYg0lj5AAAATnkuPr744gv98Ic/VMeOHdWmTRudccYZeuutt0LvG2N09913q2vXrmrTpo0KCwu1adOmiCYNIP4wdwA4xFPxsXv3bg0cOFDJyclatmyZ1q9fr9/+9rdq3759KOahhx7S448/rrlz52rNmjVq166dioqKVFNTE/HkAcQH5g4AjXna8/Hggw+qe/fumjdvXuhYz549Q/9tjNGjjz6qO++8UyNHjpQkzZ8/X9nZ2VqyZImuuuqqCKUNIJ4wdwBozNPKx9/+9jedc845+sEPfqAuXbrorLPO0lNPPRV6f8uWLSovL1dhYWHoWGZmpgYMGKDS0tIjjllbW6uqqqqwF4CWhbkDQGOeVj4+/fRTzZkzR5MnT9avf/1rvfnmm/r5z3+ulJQUjR8/XuXl5ZKk7OzssN/Lzs4OvfdN06dP17Rp05qYvpTYpbN1bEP5TvuBS9+zCjMmaD2kbQcL0NI0x7kDQOx4WvkIBoM6++yzdf/99+uss87STTfdpBtvvFFz585tcgJTpkxRZWVl6LV9+/YmjwWgeWLuANCYp+Kja9euOu2008KOnXrqqdq2bZskKScnR5JUUVERFlNRURF675tSU1Pl9/vDXgBaFuYOAI15Kj4GDhyojRs3hh37+OOP1aNHD0kHN5Dl5ORo5cqVoferqqq0Zs0aFRQURCBdAPGIuQNAY572fEyaNEkXXHCB7r//fl155ZV644039Pvf/16///3vJUk+n08TJ07Ufffdp169eqlnz5666667lJubq1GjRkUjfwBxgLkDQGOeio9zzz1Xixcv1pQpU3TvvfeqZ8+eevTRR3XNNdeEYn75y19q3759uummm7Rnzx4NGjRIL730ktLS0iKePID4wNwBoDGfMcbEOonGqqqqlJmZqYs0Ukm+5GPGJ6SkWI8drKuzT8Rn+Y2Uh26XhLZtrWOD+/fbjXnWaccOOjTm2+utYyuvtV/q3pdj93yd3Idftx7Ti23TLrCOzZsanRxamgZTr1VaqsrKyrjZS3Fo7tj98UnyZyTGOh3gmFraM3O8zBs82wUAADhF8QEAAJyi+AAAAE5RfAAAAKc8dbs0Rwk5XexjPWxObdj8aVPSOSrbTaSexvSwidSLzGeO/DyNI8ZGJQN7bCIFvGtpmx0RX1j5AAAATlF8AAAApyg+AACAUxQfAADAKYoPAADgVNx3uzRs+9w6NrHfqdaxNZedZxX35Y8OWI/Zfcz71rG+xMjfHvrctfa3l3/jrGPf2v6QpC6drOI+erC79Zi9rltrHQvAu+Vl78Y6hbhBZ1DksfIBAACcovgAAABOUXwAAACnKD4AAIBTFB8AAMCpuO928SL44cfWself2T0zJu35CusxfUn2HSQyQbuwQMB6yDfO9NJBY3d+SWqo2GkV1+s6uzgALR8dJK0bKx8AAMApig8AAOAUxQcAAHCK4gMAADhF8QEAAJyK/24Xn339lNihvXVsww7LLhbLrhRJ8iWnWscGD9g/M8bW/tHnW8dmvLLROjbw9W6ruKTOds+AkaSGL7+yjgUQf+Lp2TJ05kQeKx8AAMApig8AAOAUxQcAAHCK4gMAADgV9xtOE5LtL8HLJsaEtm2t4oL791uPOWfjCuvYm/MGWcfaavs/q61j7W/abo9NpEB8YsMlIo2VDwAA4BTFBwAAcIriAwAAOEXxAQAAnKL4AAAATsV9t0uwrs46NiElxT7W8lbsXrpdotHBAgCH0JWCeMHKBwAAcIriAwAAOEXxAQAAnKL4AAAATlF8AAAAp+K+2yUhNc06NlhbYz9wtl23i29HufWQX/1kgP3pl22zimvY9rn1mPLZ15oJaanWscEDB+xzABA1y8vejXUKMUfHT3xg5QMAADhF8QEAAJyi+AAAAE5RfAAAAKcoPgAAgFNx3+3ipYMloU0b+3HXfmAX6KGDpP0G+1xtu1ii1e1DBwuAaKIrpXVj5QMAADjlqfi455575PP5wl59+vQJvV9TU6Pi4mJ17NhR6enpGj16tCoqKiKeNID4wtwBoDHPKx+nn366duzYEXq99tprofcmTZqk559/XosWLVJJSYnKysp0xRVXRDRhAPGJuQPAIZ73fCQlJSknJ+ew45WVlfrDH/6gBQsWaPDgwZKkefPm6dRTT9Xq1at1/vnnH3+2AOIWcweAQzyvfGzatEm5ubk66aSTdM0112jbtoO3AV+7dq3q6+tVWFgYiu3Tp4/y8vJUWlr6rePV1taqqqoq7AWg5WHuAHCIp5WPAQMG6Omnn1bv3r21Y8cOTZs2TRdeeKE++OADlZeXKyUlRVlZWWG/k52drfLyb3/+yfTp0zVt2rQmJe+Vqauzjv3s/gus4k68Y7X1mE/Mf9I69hc97M7v6Xk1QIzE+9zR2tGZgkjzVHwMGzYs9N/9+vXTgAED1KNHD/3lL39RGw9trI1NmTJFkydPDv1cVVWl7t27N2ksAM0TcweAxo6r1TYrK0vf+c53tHnzZuXk5Kiurk579uwJi6moqDji97yHpKamyu/3h70AtGzMHUDrdlzFx969e/XJJ5+oa9euys/PV3JyslauXBl6f+PGjdq2bZsKCgqOO1EALQdzB9C6efra5fbbb9eIESPUo0cPlZWVaerUqUpMTNS4ceOUmZmpG264QZMnT1aHDh3k9/t16623qqCggN3qQCvH3AGgMU/Fx+eff65x48Zp165d6ty5swYNGqTVq1erc+fOkqSZM2cqISFBo0ePVm1trYqKijR79uyoJN4UJmisY09+aL1VXMAErcf8+Q+LrWN9etsq7rPn7DeCnXjV+9ax8nBdm353nlVcr5++ZX9+Lzzkas3DbfOTep9sHduwYZN1rO2t8+Nh03G8zx2t3fKyd2OdAuJAVXVA7b9jF+up+Fi4cOFR309LS9OsWbM0a9YsL8MCaOGYOwA0xrNdAACAUxQfAADAKYoPAADgFMUHAABwyvOD5ZqbxG/ckvlovr7sVOvYzGfWNCGbo/P9r10Hixcnjo39LvReN78R6xQiz0MHjZcOFi/ioYsFzQu3QUcsNZh6SZ9axbLyAQAAnKL4AAAATlF8AAAApyg+AACAUxQfAADAqbjvdgl84zHcR5M5v9Q6NvF0uxvUBz782HpMAADAygcAAHCM4gMAADhF8QEAAJyi+AAAAE5RfAAAAKfivtslWrZf2skqLjdK3S5li0+3iuv2/9mPGVz3YROzARAPlpfF/llPtngOTevGygcAAHCK4gMAADhF8QEAAJyi+AAAAE61qg2nST26W8d2ff2AVVziGX2sxwy8v8E6Nvdyu82hQesRAeDf2PCJWGLlAwAAOEXxAQAAnKL4AAAATlF8AAAApyg+AACAU62q26Vh63brWJ9lrMnv29R0ACBmvNyKnc4YRBorHwAAwCmKDwAA4BTFBwAAcIriAwAAOEXxAQAAnIr7bpfE9HTr2MDevdaxSV1zrOIa1q23HtOLhLZtreKC+/dH5fwAcAidMYg0Vj4AAIBTFB8AAMApig8AAOAUxQcAAHCK4gMAADgV990uXjpYvHTGNOwotwv02ddvZf95gXVst3/ssQt8177bJrFDe+vYwNe7rWMB4BAvnTG26KBpeVj5AAAATlF8AAAApyg+AACAUxQfAADAKYoPAADgVNx3u3jpNvniT3nWsTmjLLtITNB6zNyHX7eOtR/VHh0sQHyi2wMtzXGtfDzwwAPy+XyaOHFi6FhNTY2Ki4vVsWNHpaena/To0aqoqDjePAG0EMwbAJpcfLz55pv63e9+p379+oUdnzRpkp5//nktWrRIJSUlKisr0xVXXHHciQKIf8wbAKQmFh979+7VNddco6eeekrt2//7xlWVlZX6wx/+oBkzZmjw4MHKz8/XvHnz9Prrr2v16tURSxpA/GHeAHBIk4qP4uJiDR8+XIWFhWHH165dq/r6+rDjffr0UV5enkpLS484Vm1traqqqsJeAFqeSM4bEnMHEM88bzhduHCh1q1bpzfffPOw98rLy5WSkqKsrKyw49nZ2SovP/LtyqdPn65p06Z5TePfPGz4POGH26xjA5ZxvsRE6zFNwHZUKalzJ6u4hi+/sh4TiJVIzxtSBOaOOBKNW5ZHC5tjYcPTysf27dv1i1/8Qn/+85+VlpYWkQSmTJmiysrK0Gv79u0RGRdA8xCNeUNi7gDimafiY+3atdq5c6fOPvtsJSUlKSkpSSUlJXr88ceVlJSk7Oxs1dXVac+ePWG/V1FRoZycnCOOmZqaKr/fH/YC0HJEY96QmDuAeObpa5eLL75Y77//ftix66+/Xn369NGvfvUrde/eXcnJyVq5cqVGjx4tSdq4caO2bdumgoKCyGUNIG4wbwD4Jk/FR0ZGhvr27Rt2rF27durYsWPo+A033KDJkyerQ4cO8vv9uvXWW1VQUKDzzz8/clkDiBvMGwC+KeJ3OJ05c6YSEhI0evRo1dbWqqioSLNnz470aQC0IMwbQOviM8aYWCfRWFVVlTIzM3WRRirJlxzrdI7Nw+3dE9tnWsdyK3TEUoOp1yotVWVlZdzspTg0d+z++CT5M+y70HBsdLDAhpd5gwfLAQAApyg+AACAUxQfAADAKYoPAADgFMUHAABwKuKttq4lpKRYxwbr6uwHtu1i8fBsGS8dLAlt2ljF+U7qbn/+Dz+2jk3M9NCZU1lpHQsg/vBsGUQaKx8AAMApig8AAOAUxQcAAHCK4gMAADhF8QEAAJyK+26XYH1DVMZN6plnFdfw6WdROX/wwAG7QA8dLF7QwQK0bHSFIJZY+QAAAE5RfAAAAKcoPgAAgFMUHwAAwKm433Dq5fbm1rdMV3Q2kn51ywXWsZ3mvG4X6OGaEtPbWccG9u6zjrU+f3sPt2z3cCt6AN7F0y3TY43NuZHHygcAAHCK4gMAADhF8QEAAJyi+AAAAE5RfAAAAKfiv9vFCw+dMUldc6ziGnaUW49p3cEiyZeYaBVnAgHrMb8e1dc6NvOZUutYW3SwAGgKuk1aHlY+AACAUxQfAADAKYoPAADgFMUHAABwiuIDAAA4FffdLgmpadaxe/+Wax3bduhnTcjm6JK6nWAde+C0rlZxyf94y3rMaHSwAEBjdKbABisfAADAKYoPAADgFMUHAABwiuIDAAA4RfEBAACcivtuF9NQbx3rv8X+2S7BlBS7uNoa6zEbPv/COjb5ix1WcYln9LEeM/D+ButYAGiK5WXvxvT8dNvEB1Y+AACAUxQfAADAKYoPAADgFMUHAABwKv43nAYC1rENn35mHZvUo7tVnK9tG+sxAx99bB0rY7c5lk2kAJqCjZmIJVY+AACAUxQfAADAKYoPAADgFMUHAABwiuIDAAA4FffdLl74kpKtY4Nf7rKKOzC4r/WYqR9ZhwIA0GKx8gEAAJzyVHzMmTNH/fr1k9/vl9/vV0FBgZYtWxZ6v6amRsXFxerYsaPS09M1evRoVVRURDxpAPGFuQNAY56Kj27duumBBx7Q2rVr9dZbb2nw4MEaOXKkPvzwQ0nSpEmT9Pzzz2vRokUqKSlRWVmZrrjiiqgkDiB+MHcAaMxnjDHHM0CHDh308MMPa8yYMercubMWLFigMWPGSJI2bNigU089VaWlpTr//POtxquqqlJmZqYu0kgl+ez3aNjwsufDl2IX62nPxwtvWMcCsdRg6rVKS1VZWSm/3x+Vc0Rr7tj98UnyZyRGJeeWhDucItK8zBtN3vMRCAS0cOFC7du3TwUFBVq7dq3q6+tVWFgYiunTp4/y8vJUWlr6rePU1taqqqoq7AWg5WLuAOC52+X9999XQUGBampqlJ6ersWLF+u0007TO++8o5SUFGVlZYXFZ2dnq7y8/FvHmz59uqZNm+Y58aYwDfXWsYGBZ1jFsZoB2InnuaMlWl72rnUsqySINM8rH71799Y777yjNWvW6JZbbtH48eO1fv36JicwZcoUVVZWhl7bt29v8lgAmi/mDgCHeF75SElJ0SmnnCJJys/P15tvvqnHHntMY8eOVV1dnfbs2RP2L5iKigrl5OR863ipqalKTU31njmAuMLcAeCQ477PRzAYVG1trfLz85WcnKyVK1eG3tu4caO2bdumgoKC4z0NgBaGuQNovTytfEyZMkXDhg1TXl6eqqurtWDBAq1atUrLly9XZmambrjhBk2ePFkdOnSQ3+/XrbfeqoKCAuvd6gBaJuYOAI15Kj527typH/3oR9qxY4cyMzPVr18/LV++XN///vclSTNnzlRCQoJGjx6t2tpaFRUVafbs2VFJHED8YO4A0Nhx3+cj0qJ5n4/dP7Zfwm3/x29v8WvMl2h/P4GE03pZxwY/+sQqzgQC1mPKBO1j0aq5uM9HpHGfj5aLbpv44OQ+HwAAAE1B8QEAAJyi+AAAAE5RfAAAAKcoPgAAgFOe73Da7Pjs6yfbDhZPp/fwpNz6Dm2tY2336vsSfNZjGg+NMQAARAsrHwAAwCmKDwAA4BTFBwAAcIriAwAAOBX3G04T/RnWsS9+9Kp1rO3tfL3c3jzxtXetYwMX2p0/YdU66zEBINq4FTpssPIBAACcovgAAABOUXwAAACnKD4AAIBTFB8AAMCpuO92CVRWWscOuXK8dazP955VXGJutvWYDdvLrGONz/626QAAxBNWPgAAgFMUHwAAwCmKDwAA4BTFBwAAcIriAwAAOBX33S7y2ddPyZvsu00abOO2fW49pheJr6yNyrgAIPEMFsQWKx8AAMApig8AAOAUxQcAAHCK4gMAADhF8QEAAJyK/24XD8z+Ax6Cg1ZhCSkp1kP62rSxjg1UVVvFJXVobz1mw65d1rEAWrblZe/GOoW4QWdQ5LHyAQAAnKL4AAAATlF8AAAApyg+AACAU/G/4dRyY6gkBartNnFKUoLl5tCd151lPWbnp960jk3q0skqrqFip/WYABBtbM6EDVY+AACAUxQfAADAKYoPAADgFMUHAABwiuIDAAA4Ff/dLtESNFZh2c99ZD2kL7uz/fnT29rF0e0CAIgzrHwAAACnKD4AAIBTFB8AAMApig8AAOAUxQcAAHCqVXW72D6vRZKCNbV2Y/Y5yXrM/P//fevYN85MtI4FgGjieS2INFY+AACAU56Kj+nTp+vcc89VRkaGunTpolGjRmnjxo1hMTU1NSouLlbHjh2Vnp6u0aNHq6KiIqJJA4gvzB0AGvNUfJSUlKi4uFirV6/WihUrVF9fryFDhmjfvn2hmEmTJun555/XokWLVFJSorKyMl1xxRURTxxA/GDuANCYzxhjdyvPI/jyyy/VpUsXlZSU6D/+4z9UWVmpzp07a8GCBRozZowkacOGDTr11FNVWlqq888//5hjVlVVKTMzUxdppJJ8yU1N7YiisuejXx/rMc9hzwfiRIOp1yotVWVlpfx+f8THj+bcsfvjk+TP4M9PJLHnAza8zBvHteejsrJSktShQwdJ0tq1a1VfX6/CwsJQTJ8+fZSXl6fS0tIjjlFbW6uqqqqwF4CWjbkDaN2a3O0SDAY1ceJEDRw4UH379pUklZeXKyUlRVlZWWGx2dnZKi8vP+I406dP17Rp05qahhIzM61jA/834dn45NFj/0tLkk6euNp6TFYzgOYzd7RErFAgXjR55aO4uFgffPCBFi5ceFwJTJkyRZWVlaHX9u3bj2s8AM0bcweAJq18TJgwQS+88IJeffVVdevWLXQ8JydHdXV12rNnT9i/YCoqKpSTk3PEsVJTU5WamtqUNADEGeYOAJLHlQ9jjCZMmKDFixfr5ZdfVs+ePcPez8/PV3JyslauXBk6tnHjRm3btk0FBQWRyRhA3GHuANCYp5WP4uJiLViwQEuXLlVGRkbou9jMzEy1adNGmZmZuuGGGzR58mR16NBBfr9ft956qwoKCqx2qwNomZg7ADTmqfiYM2eOJOmiiy4KOz5v3jxdd911kqSZM2cqISFBo0ePVm1trYqKijR79uyIJAsgPjF3AGjsuO7zEQ2e7/Phs//mKLHPKdaxvmDQKq7h40+tx0zKO8E6NvDFkXf4f5NpqLceE7AV7ft8RAP3+YgvdOa0PM7u8wEAAOAVxQcAAHCK4gMAADhF8QEAAJxq8u3Vmw1jtzFUklRm/3juhqrqiJ8/mJVhHWu2RuFujR4259YOP8c6NvWFN5qSTcQk9bbfSNywcXMUMwFga3nZu7FOIeZa86ZbVj4AAIBTFB8AAMApig8AAOAUxQcAAHCK4gMAADgV/90uHvjatbUPrqy0Ckvs29t6yMC7661jP33E7kmeua8GrMdM+5t9V0qsO1i8oIMFiD+tudMDrHwAAADHKD4AAIBTFB8AAMApig8AAOAUxQcAAHCqVXW7BHZ+ZR2bkJpmFbf/xEzrMdM+SrSOPen2UutYAIgmOlMQaax8AAAApyg+AACAUxQfAADAKYoPAADgFMUHAABwKu67XXyJ9h0kMkHr0ISOnaziJs5cYD3mnBdOsY4FgGiigwWxxMoHAABwiuIDAAA4RfEBAACcovgAAABOxf2GUxMIRGXc4O49VnFPff9i+0F925uWzNF42UR79un2seVfW8c2lO2wjgXQPCwvezfWKUQFG2njAysfAADAKYoPAADgFMUHAABwiuIDAAA4RfEBAACcivtuFy8S+/a2jg18sNEqLvjZ1qam41xw3Yf2sVHMA0Ds0RWCWGLlAwAAOEXxAQAAnKL4AAAATlF8AAAApyg+AACAU3Hf7VJ1TYF1rP/PpVHMBACig84UtDSsfAAAAKcoPgAAgFMUHwAAwCmKDwAA4BTFBwAAcCruu138C9ZYx+7+sX1nTPs/2nXG+BITrcc0QWMdm5R3glVc4Ity+/M31NufP7uLdWywqtou7sAB6zEB/NvysndjnUKLQwdRbLHyAQAAnPJcfLz66qsaMWKEcnNz5fP5tGTJkrD3jTG6++671bVrV7Vp00aFhYXatGlTpPIFEIeYNwA05rn42Ldvn/r3769Zs2Yd8f2HHnpIjz/+uObOnas1a9aoXbt2KioqUk1NzXEnCyA+MW8AaMzzno9hw4Zp2LBhR3zPGKNHH31Ud955p0aOHClJmj9/vrKzs7VkyRJdddVVx5ctgLjEvAGgsYju+diyZYvKy8tVWFgYOpaZmakBAwaotPTIGzhra2tVVVUV9gLQejRl3pCYO4B4FtFul/Lyg50X2dnZYcezs7ND733T9OnTNW3atKaf1AStQ207WCRJPru6rHzCAOshsx973Tq2Yet261hbwYvOtj//qnURPz9wJE2ZN6QIzB2IG3SmtDwx73aZMmWKKisrQ6/t2yP/ly6Aloe5A4hfES0+cnJyJEkVFRVhxysqKkLvfVNqaqr8fn/YC0Dr0ZR5Q2LuAOJZRIuPnj17KicnRytXrgwdq6qq0po1a1RQYH+DLwCtB/MG0Pp43vOxd+9ebd68OfTzli1b9M4776hDhw7Ky8vTxIkTdd9996lXr17q2bOn7rrrLuXm5mrUqFGRzBtAHGHeANCY5+Ljrbfe0ve+973Qz5MnT5YkjR8/Xk8//bR++ctfat++fbrpppu0Z88eDRo0SC+99JLS0tIil3VjlhtDJSkh2f5yg3V1VnE5s960HtP+5ur2knp0t45lEylipdnNGwBiymeMicbfiU1WVVWlzMxMXaSRSvIlH/sXYlx8+JIscvw/Xp6tYstT8RGFDhq0TA2mXqu0VJWVlXGzl+LQ3LH745Pkz7B/5hKaP7pd4oOXeSPm3S4AAKB1ofgAAABOUXwAAACnKD4AAIBTEb29ekx4uL36gaIzrWNTn3/DKm7rnedaj5l3j/3t1W2xiRRAtLHhE5HGygcAAHCK4gMAADhF8QEAAJyi+AAAAE5RfAAAAKfiv9vFg+SqhoiP6aWDJda3YgcAoDlg5QMAADhF8QEAAJyi+AAAAE5RfAAAAKcoPgAAgFNx3+2S1KO7dWxDyTrr2MSsLKu4wJ491mMmtGtrHRvcu9cqrvKq86zH9P+51DoWAA5ZXvZuxMfkeTGtGysfAADAKYoPAADgFMUHAABwiuIDAAA4FfcbThu2breOTerY0Tq2z4o9VnEfnG09pM4ssRtTktae6bOKq+lgFydJfutIAACih5UPAADgFMUHAABwiuIDAAA4RfEBAACcovgAAABOxX23S2JGhnWsl1uhf3B2wC7QZ1+/rT3LOlRS0Coqd8WX1iM2eDk9AABRwsoHAABwiuIDAAA4RfEBAACcovgAAABOUXwAAACn4r7bJVBdbR2bkJJiHWsClt0uxq4rRZIS09OtYwP79lvFNWzYZD2mJx66eKz/N/AwZkOh/UNzUtd+Yh0b+Hq3dSyA6Fle9m6sU4i5otz+sU4hZlj5AAAATlF8AAAApyg+AACAUxQfAADAKYoPAADgVNx3u3gRrKuzD7bszPAlJtqPeeIJ9qff8KlVnDmvn/35X3/HPtZDF080xkxa8ZZ1rGVfEoBmpDV3eoCVDwAA4BjFBwAAcIriAwAAOEXxAQAAnKL4AAAATrWqbhcvtt95vlVc9/tWW4/p21VpHWsa6u0CS9+zHjNqLDuDLl+/03rI50ecZx3bsNmuMwhA89FSn+1CF4+dqK18zJo1SyeeeKLS0tI0YMAAvfHGG9E6FYAWgnkDaB2iUnw899xzmjx5sqZOnap169apf//+Kioq0s6d9v/yBdC6MG8ArUdUio8ZM2boxhtv1PXXX6/TTjtNc+fOVdu2bfXHP/4xGqcD0AIwbwCtR8T3fNTV1Wnt2rWaMmVK6FhCQoIKCwtVWlp6WHxtba1qa2tDP1dWHtwX0aB6yUQ6O3uB2hqruAZjuTdDkoL2d1i1H9dD/RiNu5Z6yOHA3gbrERsCtccOOhTr5TOAlQYd/N/UGDd/CL3OG9K3zx1Ve6P1/3Pg2FrzfORl3oh48fHVV18pEAgoOzs77Hh2drY2bNhwWPz06dM1bdq0w46/phcjnZo3Dy61CtvsZczyJmVydDEs0EIsc1h1jpdBX2tKJoiw6upqZWZmRv08XucN6dvnjh5nfxaNFAFLbIC3mTdi3u0yZcoUTZ48OfTznj171KNHD23bts3JpOdKVVWVunfvru3bt8vv98c6nYhpidfVEq9J8nZdxhhVV1crNzfXUXbeMXfEr5Z4TRLX5WXeiHjx0alTJyUmJqqioiLseEVFhXJycg6LT01NVWpq6mHHMzMzW9SHd4jf7+e64kRLvCbJ/rpc/gXudd6QmDtagpZ4TVLrvi7beSPiG05TUlKUn5+vlStXho4Fg0GtXLlSBQUFkT4dgBaAeQNoXaLytcvkyZM1fvx4nXPOOTrvvPP06KOPat++fbr++uujcToALQDzBtB6RKX4GDt2rL788kvdfffdKi8v15lnnqmXXnrpsM1kR5KamqqpU6cecTk1nnFd8aMlXpPU/K/reOYNqflfX1O1xOtqidckcV1e+IyrXjoAAADxYDkAAOAYxQcAAHCK4gMAADhF8QEAAJyi+AAAAE41u+Jj1qxZOvHEE5WWlqYBAwbojTfeiHVKx+Wee+6Rz+cLe/Xp0yfWaXny6quvasSIEcrNzZXP59OSJUvC3jfG6O6771bXrl3Vpk0bFRYWatOmTbFJ1oNjXdd111132Gc3dOjQ2CRrafr06Tr33HOVkZGhLl26aNSoUdq4cWNYTE1NjYqLi9WxY0elp6dr9OjRh91ZNN4wbzRPzB3MHd+mWRUfzz33nCZPnqypU6dq3bp16t+/v4qKirRz585Yp3ZcTj/9dO3YsSP0eu21+Hpo2r59+9S/f3/NmjXriO8/9NBDevzxxzV37lytWbNG7dq1U1FRkWpq7J4MHCvHui5JGjp0aNhn9+yzzzrM0LuSkhIVFxdr9erVWrFiherr6zVkyBDt27cvFDNp0iQ9//zzWrRokUpKSlRWVqYrrrgihlkfH+aN5ou5g7njW5lm5LzzzjPFxcWhnwOBgMnNzTXTp0+PYVbHZ+rUqaZ///6xTiNiJJnFixeHfg4GgyYnJ8c8/PDDoWN79uwxqamp5tlnn41Bhk3zzesyxpjx48ebkSNHxiSfSNm5c6eRZEpKSowxBz+b5ORks2jRolDMRx99ZCSZ0tLSWKV5XJg34gNzR3yJ9tzRbFY+6urqtHbtWhUWFoaOJSQkqLCwUKWlpTHM7Pht2rRJubm5Oumkk3TNNddo27ZtsU4pYrZs2aLy8vKwzy0zM1MDBgyI+89NklatWqUuXbqod+/euuWWW7Rr165Yp+RJZWWlJKlDhw6SpLVr16q+vj7s8+rTp4/y8vLi8vNi3ohfzB3NW7TnjmZTfHz11VcKBAKH3Uo5Oztb5eXlMcrq+A0YMEBPP/20XnrpJc2ZM0dbtmzRhRdeqOrq6linFhGHPpuW9rlJB5dN58+fr5UrV+rBBx9USUmJhg0bpkAgEOvUrASDQU2cOFEDBw5U3759JR38vFJSUpSVlRUWG6+fF/NG/GLuaL5czB1RebYL/m3YsGGh/+7Xr58GDBigHj166C9/+YtuuOGGGGaGY7nqqqtC/33GGWeoX79+Ovnkk7Vq1SpdfPHFMczMTnFxsT744IO43CvQ2jFvxDfmjmNrNisfnTp1UmJi4mE7ZysqKpSTkxOjrCIvKytL3/nOd7R58+ZYpxIRhz6blv65SdJJJ52kTp06xcVnN2HCBL3wwgt65ZVX1K1bt9DxnJwc1dXVac+ePWHx8fp5MW/EL+aO5snV3NFsio+UlBTl5+dr5cqVoWPBYFArV65UQUFBDDOLrL179+qTTz5R165dY51KRPTs2VM5OTlhn1tVVZXWrFnToj43Sfr888+1a9euZv3ZGWM0YcIELV68WC+//LJ69uwZ9n5+fr6Sk5PDPq+NGzdq27Ztcfl5MW/EL+aO5sX53BGhjbERsXDhQpOammqefvpps379enPTTTeZrKwsU15eHuvUmuy2224zq1atMlu2bDH/+te/TGFhoenUqZPZuXNnrFOzVl1dbd5++23z9ttvG0lmxowZ5u233zZbt241xhjzwAMPmKysLLN06VLz3nvvmZEjR5qePXuaAwcOxDjzozvadVVXV5vbb7/dlJaWmi1btph//vOf5uyzzza9evUyNTU1sU79W91yyy0mMzPTrFq1yuzYsSP02r9/fyjmpz/9qcnLyzMvv/yyeeutt0xBQYEpKCiIYdbHh3mj+WLuYO74Ns2q+DDGmCeeeMLk5eWZlJQUc95555nVq1fHOqXjMnbsWNO1a1eTkpJiTjjhBDN27FizefPmWKflySuvvGIkHfYaP368MeZgy9xdd91lsrOzTWpqqrn44ovNxo0bY5u0haNd1/79+82QIUNM586dTXJysunRo4e58cYbm/1faEe6Hklm3rx5oZgDBw6Yn/3sZ6Z9+/ambdu25vLLLzc7duyIXdIRwLzRPDF3MHd8G9//nRQAAMCJZrPnAwAAtA4UHwAAwCmKDwAA4BTFBwAAcIriAwAAOEXxAQAAnKL4AAAATlF8AAAApyg+AACAUxQfAADAKYoPAADg1P8DTH5EJgSE4jwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "GR7CFKiCKoLQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agwP5nY1fc7Z",
        "outputId": "d2118dd5-0cd3-497f-95a8-55923bef3e17"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ParallelMapDataset element_spec=((TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None)), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu_A-31pKq1_",
        "outputId": "79a36941-4629-4277-8d87-b86ba17b5526"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2   9 566 597 540   4   3   0   0   0]\n",
            "\n",
            "[  2  27 135 673  61   4   0   0   0   0]\n",
            "[ 27 135 673  61   4   3   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_context_tok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGY-XDtXfjb5",
        "outputId": "119bff85-74c4-4a8e-8db5-878c11856952"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 16), dtype=int64, numpy=\n",
              "array([[  2,   9, 566, ...,   0,   0,   0],\n",
              "       [  2,  13,  21, ...,   0,   0,   0],\n",
              "       [  2,  36, 530, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [  2,   9,  73, ...,   0,   0,   0],\n",
              "       [  2,   1,  83, ...,   0,   0,   0],\n",
              "       [  2,  68,  17, ...,   0,   0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNITS = 256"
      ],
      "metadata": {
        "id": "xRmis8prSpRQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ],
      "metadata": {
        "id": "T2S164F0LM9n"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJnAf6GUSV8f",
        "outputId": "8e9315c1-3bfd-425a-c43d-56f2cc96a555"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (64, 16)\n",
            "Encoder output, shape (batch, s, units): (64, 16, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_text_processor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2_CdtgVZica",
        "outputId": "87314ed6-25f4-4d2c-d835-192aa26c366f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7fd1a1148a00>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OS9ABnV1ZibA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        "\n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "uvpZaH8bSZiP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                  output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k72SldJiWHbB",
        "outputId": "54bab949-9b3a-42d3-ed85-c764007ad242"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (64, 16, 256)\n",
            "Target sequence, shape (batch, t, units): (64, 16, 256)\n",
            "Attention result, shape (batch, t, units): (64, 16, 256)\n",
            "Attention weights, shape (batch, t, s):    (64, 16, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzajM1aQdJRi",
        "outputId": "e7b5c725-e5d2-406e-dade-0ef06e46cda3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.99999994, 1.        , 0.99999994, 0.99999994,\n",
              "       1.        , 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "pHohrRcBdMTY",
        "outputId": "5b3c7e1a-5141-4643-afba-c0e2e46faf22"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ],
      "metadata": {
        "id": "gq-RYW2MdPoR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ],
      "metadata": {
        "id": "CihwpMUtdUWY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ],
      "metadata": {
        "id": "bzn8OIDDdXVR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baCPUXRpdZep",
        "outputId": "d45c3c39-d610-4e5a-d3b5-89a8d74c594a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (64, 16, 256)\n",
            "input target tokens shape: (batch, t) (64, 16)\n",
            "logits shape shape: (batch, target_vocabulary_size) (64, 16, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ],
      "metadata": {
        "id": "LavGW7mddb-x"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ],
      "metadata": {
        "id": "WFPLqXEZdb9Y"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "\n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "\n",
        "  return next_token, done, state"
      ],
      "metadata": {
        "id": "OtRjqlDbdenJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_4yefxFdkQo",
        "outputId": "023e3632-e006-45bb-9dfa-8da483ff6e46"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'bear pleaded disguised evidence recommend cookie golden plastic bleeding mistake',\n",
              "       b'driver cases japanese snore devoted barely table comparison housesitting curry',\n",
              "       b'. hell veterinarian opponent hoax offer strike scotland traffic room'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "Kq0uImBjdkPJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J66u0d0Sdow5",
        "outputId": "447e67c3-5b20-4b35-a6c6-a33e6f9c6097"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (64, 16)\n",
            "Target tokens, shape: (batch, t) (64, 16)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (64, 16, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "882xJ3A7dsch"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "pUdCbL23duHS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ],
      "metadata": {
        "id": "sCQ8tAtmdw1x"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfveydYXd6P4",
        "outputId": "6b03c18d-5bf9-454f-92aa-02e0e15778b4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 8.517193, 'expected_acc': 0.0002}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_ds, steps=20, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJU7oRfBdzBO",
        "outputId": "eb45dbea-b0e0-48a9-f3ae-27c078587f7c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 30s 332ms/step - loss: 8.5232 - masked_acc: 0.0000e+00 - masked_loss: 8.5232\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 8.523183822631836,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 8.523183822631836}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 20,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYiWH1svdy_y",
        "outputId": "8b298aea-cc22-44dd-cf96-f08ee92eabed"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 111s 936ms/step - loss: 4.9975 - masked_acc: 0.2728 - masked_loss: 4.9975 - val_loss: 4.0743 - val_masked_acc: 0.3550 - val_masked_loss: 4.0743\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 95s 947ms/step - loss: 3.6724 - masked_acc: 0.4079 - masked_loss: 3.6724 - val_loss: 3.2910 - val_masked_acc: 0.4584 - val_masked_loss: 3.2910\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 97s 970ms/step - loss: 3.0985 - masked_acc: 0.4853 - masked_loss: 3.0985 - val_loss: 2.8972 - val_masked_acc: 0.5051 - val_masked_loss: 2.8972\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 95s 945ms/step - loss: 2.7257 - masked_acc: 0.5364 - masked_loss: 2.7257 - val_loss: 2.5087 - val_masked_acc: 0.5597 - val_masked_loss: 2.5087\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 94s 943ms/step - loss: 2.4318 - masked_acc: 0.5773 - masked_loss: 2.4318 - val_loss: 2.2815 - val_masked_acc: 0.5946 - val_masked_loss: 2.2815\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 90s 905ms/step - loss: 2.1715 - masked_acc: 0.6163 - masked_loss: 2.1715 - val_loss: 2.0502 - val_masked_acc: 0.6317 - val_masked_loss: 2.0502\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 94s 946ms/step - loss: 2.0135 - masked_acc: 0.6385 - masked_loss: 2.0135 - val_loss: 1.9082 - val_masked_acc: 0.6523 - val_masked_loss: 1.9082\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 93s 926ms/step - loss: 1.8798 - masked_acc: 0.6573 - masked_loss: 1.8798 - val_loss: 1.7976 - val_masked_acc: 0.6657 - val_masked_loss: 1.7976\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 94s 942ms/step - loss: 1.7766 - masked_acc: 0.6723 - masked_loss: 1.7766 - val_loss: 1.7430 - val_masked_acc: 0.6767 - val_masked_loss: 1.7430\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 90s 901ms/step - loss: 1.6659 - masked_acc: 0.6876 - masked_loss: 1.6659 - val_loss: 1.6087 - val_masked_acc: 0.6940 - val_masked_loss: 1.6087\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 97s 976ms/step - loss: 1.6185 - masked_acc: 0.6933 - masked_loss: 1.6185 - val_loss: 1.5724 - val_masked_acc: 0.6979 - val_masked_loss: 1.5724\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 92s 911ms/step - loss: 1.5227 - masked_acc: 0.7072 - masked_loss: 1.5227 - val_loss: 1.4828 - val_masked_acc: 0.7103 - val_masked_loss: 1.4828\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 92s 916ms/step - loss: 1.5080 - masked_acc: 0.7101 - masked_loss: 1.5080 - val_loss: 1.4904 - val_masked_acc: 0.7112 - val_masked_loss: 1.4904\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 92s 921ms/step - loss: 1.5015 - masked_acc: 0.7106 - masked_loss: 1.5015 - val_loss: 1.4321 - val_masked_acc: 0.7154 - val_masked_loss: 1.4321\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 98s 982ms/step - loss: 1.4396 - masked_acc: 0.7175 - masked_loss: 1.4388 - val_loss: 1.4101 - val_masked_acc: 0.7227 - val_masked_loss: 1.4101\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 97s 966ms/step - loss: 1.2189 - masked_acc: 0.7445 - masked_loss: 1.2189 - val_loss: 1.3766 - val_masked_acc: 0.7254 - val_masked_loss: 1.3766\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 98s 983ms/step - loss: 1.2315 - masked_acc: 0.7426 - masked_loss: 1.2315 - val_loss: 1.3887 - val_masked_acc: 0.7259 - val_masked_loss: 1.3887\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 96s 961ms/step - loss: 1.1898 - masked_acc: 0.7522 - masked_loss: 1.1898 - val_loss: 1.3651 - val_masked_acc: 0.7291 - val_masked_loss: 1.3651\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 95s 952ms/step - loss: 1.2104 - masked_acc: 0.7467 - masked_loss: 1.2104 - val_loss: 1.3067 - val_masked_acc: 0.7342 - val_masked_loss: 1.3067\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 99s 991ms/step - loss: 1.1740 - masked_acc: 0.7519 - masked_loss: 1.1740 - val_loss: 1.3710 - val_masked_acc: 0.7269 - val_masked_loss: 1.3710\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 95s 950ms/step - loss: 1.1944 - masked_acc: 0.7491 - masked_loss: 1.1944 - val_loss: 1.3054 - val_masked_acc: 0.7359 - val_masked_loss: 1.3054\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 95s 954ms/step - loss: 1.1924 - masked_acc: 0.7491 - masked_loss: 1.1924 - val_loss: 1.3322 - val_masked_acc: 0.7333 - val_masked_loss: 1.3322\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 91s 916ms/step - loss: 1.1677 - masked_acc: 0.7557 - masked_loss: 1.1677 - val_loss: 1.2571 - val_masked_acc: 0.7446 - val_masked_loss: 1.2571\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 95s 953ms/step - loss: 1.1621 - masked_acc: 0.7564 - masked_loss: 1.1621 - val_loss: 1.2318 - val_masked_acc: 0.7458 - val_masked_loss: 1.2318\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 93s 923ms/step - loss: 1.1483 - masked_acc: 0.7587 - masked_loss: 1.1483 - val_loss: 1.2819 - val_masked_acc: 0.7428 - val_masked_loss: 1.2819\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 95s 955ms/step - loss: 1.1355 - masked_acc: 0.7589 - masked_loss: 1.1355 - val_loss: 1.2530 - val_masked_acc: 0.7413 - val_masked_loss: 1.2530\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 89s 890ms/step - loss: 1.1373 - masked_acc: 0.7595 - masked_loss: 1.1373 - val_loss: 1.2500 - val_masked_acc: 0.7424 - val_masked_loss: 1.2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xUI4nIuceL1z"
      },
      "execution_count": 47,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT+gCwCHpmVSBsCPCwBWez",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}